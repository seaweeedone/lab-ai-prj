{
  "name": "org_code_iris",
  "framework": "tensorflow",
  "metric": ["accuracy"],
  "parameter": "parser.add_argument('--batch-size', type=int, default=5,\n                        help='input batch size for training (default: 5)')\nparser.add_argument('--learning-rate', type=float, default=0.001,\n                        help='learning rate (default: 0.001)')\nparser.add_argument('--epochs', type=int, default=100, metavar='N',\n                        help='number of epochs to train (default: 100)')",
  "model_block": "import argparse\nimport os\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\n\ndef iris_model():\n    model = Sequential()\n    model.add(Dense(10, input_shape=(4,), activation='relu', name='fc1'))\n    model.add(Dense(10, activation='relu', name='fc2'))\n    model.add(Dense(3, activation='softmax', name='output'))\n    return model\n\nclass MetricsPrint(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        \"\"\"\n        Simple function for printing the history so that Katib picks it up\n        \"\"\"\n        hist = self.model.history.history\n        history_keys = list(hist.keys())\n        print('\\nepoche {}:'.format(epoch))\n        for cur_key in history_keys:\n            print('{}={}'.format(cur_key,hist[cur_key][-1]))",
  "data_block": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--batch-size', type=int, default=5,\n                        help='input batch size for training (default: 5)')\n    parser.add_argument('--learning-rate', type=float, default=0.001,\n                        help='learning rate (default: 0.001)')\n    parser.add_argument('--epochs', type=int, default=100, metavar='N',\n                        help='number of epochs to train (default: 100)')\n    args = parser.parse_args(args=[])\n\n    iris_data = load_iris()\n    print('Example data: ')\n    print(iris_data.data[:5])\n    print('Example labels: ')\n    print(iris_data.target[:5])\n    x = iris_data.data\n    y_ = iris_data.target.reshape(-1, 1)\n\n    encoder = OneHotEncoder(sparse=False)\n    y = encoder.fit_transform(y_)\n\n    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)\n    model = iris_model()\n\n    optimizer = Adam(learning_rate=args.learning_rate)\n    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n    print('Neural Network Model Summary: ')\n    print(model.summary())\n\n    history = model.fit(train_x, train_y, verbose=0, batch_size=args.batch_size, epochs=args.epochs, callbacks=[MetricsPrint()])\n\nif __name__ == \"__main__\":\n    main()"
}
